{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e296abcc-c068-4439-aa40-9ee920a5f9d5",
   "metadata": {},
   "source": [
    "# HW2 2017170858 김호송"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac295ad1-7667-4567-bcf8-af58c9ea2c7b",
   "metadata": {},
   "source": [
    "## 7.1. From Fully Connected Layers to Convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a7f904-3e68-418d-99f8-f7bac77b8e5e",
   "metadata": {},
   "source": [
    "### Take away messages and discussion points\n",
    "\n",
    "CSV Files: Data is often stored in CSV format, which can be easily loaded using the pandas library.\n",
    "\n",
    "Handling Missing Data: Missing values (NaN) can be dealt with using imputation (replacing with estimates) or by deleting rows or columns.\n",
    "\n",
    "Categorical Data: Categorical fields can be transformed using get_dummies to create separate binary columns for each category.\n",
    "\n",
    "Numerical Imputation: Missing numerical values can be filled using the mean value of the column, which helps in handling incomplete datasets.\n",
    "\n",
    "Tensor Conversion: After preprocessing, we can convert the data into tensor format for deep learning purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54b8f9b-0951-49ec-bccb-93d047a27718",
   "metadata": {},
   "source": [
    "## 7.2. Convolutions for Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba8d3770-d5bf-45f7-aafe-cb892b6d1da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\anaconda\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: filelock in c:\\anaconda\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\anaconda\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\anaconda\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\anaconda\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\anaconda\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\anaconda\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\anaconda\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\anaconda\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\anaconda\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "001bec22-3d76-4e60-b9b9-a766d6b397bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\anaconda\\lib\\site-packages (24.2)\n",
      "Requirement already satisfied: setuptools in c:\\anaconda\\lib\\site-packages (75.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip setuptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "727374a0-79c0-4230-8a72-65717282d5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wheel in c:\\anaconda\\lib\\site-packages (0.43.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wheel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d675b23-68f2-4bbb-ae9b-94e0d6b45e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting d2l\n",
      "  Using cached d2l-1.0.3-py3-none-any.whl.metadata (556 bytes)\n",
      "Requirement already satisfied: jupyter==1.0.0 in c:\\anaconda\\lib\\site-packages (from d2l) (1.0.0)\n",
      "Collecting numpy==1.23.5 (from d2l)\n",
      "  Using cached numpy-1.23.5.tar.gz (10.7 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Getting requirements to build wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [33 lines of output]\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\anaconda\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n",
      "      main()\n",
      "    File \"C:\\anaconda\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n",
      "      json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\anaconda\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 112, in get_requires_for_build_wheel\n",
      "      backend = _build_backend()\n",
      "                ^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\anaconda\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 77, in _build_backend\n",
      "      obj = import_module(mod_path)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\anaconda\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "      return _bootstrap._gcd_import(name[level:], package, level)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
      "    File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "    File \"<frozen importlib._bootstrap>\", line 1310, in _find_and_load_unlocked\n",
      "    File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
      "    File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
      "    File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "    File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n",
      "    File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n",
      "    File \"<frozen importlib._bootstrap_external>\", line 995, in exec_module\n",
      "    File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
      "    File \"C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\pip-build-env-gjjqzdox\\overlay\\Lib\\site-packages\\setuptools\\__init__.py\", line 16, in <module>\n",
      "      import setuptools.version\n",
      "    File \"C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\pip-build-env-gjjqzdox\\overlay\\Lib\\site-packages\\setuptools\\version.py\", line 1, in <module>\n",
      "      import pkg_resources\n",
      "    File \"C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\pip-build-env-gjjqzdox\\overlay\\Lib\\site-packages\\pkg_resources\\__init__.py\", line 2172, in <module>\n",
      "      register_finder(pkgutil.ImpImporter, find_on_path)\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  AttributeError: module 'pkgutil' has no attribute 'ImpImporter'. Did you mean: 'zipimporter'?\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "Getting requirements to build wheel did not run successfully.\n",
      "exit code: 1\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "pip install d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d242a17a-4176-4118-8e34-f990530d50e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting d2lNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading d2l-1.0.3-py3-none-any.whl.metadata (556 bytes)\n",
      "Requirement already satisfied: jupyter==1.0.0 in c:\\anaconda\\lib\\site-packages (from d2l) (1.0.0)\n",
      "Collecting numpy==1.23.5 (from d2l)\n",
      "  Downloading numpy-1.23.5.tar.gz (10.7 MB)\n",
      "     ---------------------------------------- 0.0/10.7 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.8/10.7 MB 6.7 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 2.6/10.7 MB 7.6 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 4.2/10.7 MB 8.1 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 6.0/10.7 MB 8.2 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 7.9/10.7 MB 8.4 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 10.0/10.7 MB 8.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 10.7/10.7 MB 8.7 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Getting requirements to build wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [33 lines of output]\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\anaconda\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n",
      "      main()\n",
      "    File \"C:\\anaconda\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n",
      "      json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\anaconda\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 112, in get_requires_for_build_wheel\n",
      "      backend = _build_backend()\n",
      "                ^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\anaconda\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 77, in _build_backend\n",
      "      obj = import_module(mod_path)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\anaconda\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "      return _bootstrap._gcd_import(name[level:], package, level)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
      "    File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "    File \"<frozen importlib._bootstrap>\", line 1310, in _find_and_load_unlocked\n",
      "    File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
      "    File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
      "    File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "    File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n",
      "    File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n",
      "    File \"<frozen importlib._bootstrap_external>\", line 995, in exec_module\n",
      "    File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
      "    File \"C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\pip-build-env-l05mrno1\\overlay\\Lib\\site-packages\\setuptools\\__init__.py\", line 16, in <module>\n",
      "      import setuptools.version\n",
      "    File \"C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\pip-build-env-l05mrno1\\overlay\\Lib\\site-packages\\setuptools\\version.py\", line 1, in <module>\n",
      "      import pkg_resources\n",
      "    File \"C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\pip-build-env-l05mrno1\\overlay\\Lib\\site-packages\\pkg_resources\\__init__.py\", line 2172, in <module>\n",
      "      register_finder(pkgutil.ImpImporter, find_on_path)\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  AttributeError: module 'pkgutil' has no attribute 'ImpImporter'. Did you mean: 'zipimporter'?\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "Getting requirements to build wheel did not run successfully.\n",
      "exit code: 1\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "pip install d2l --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bf636a0-935f-4aa6-9b6f-f8b27e5dd52c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'd2l'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01md2l\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m torch \u001b[38;5;28;01mas\u001b[39;00m d2l\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'd2l'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a89a9df-feff-43f0-8282-659ff0a50f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d(X, K):  #@save\n",
    "    \"\"\"Compute 2D cross-correlation.\"\"\"\n",
    "    h, w = K.shape\n",
    "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09aef85-b3bd-4e93-9b37-04eeb3c949a8",
   "metadata": {},
   "source": [
    "### Takeaway messages and discussion points\n",
    "\n",
    "Cross-Correlation vs Convolution:\n",
    "Convolution in deep learning often refers to cross-correlation, which is used to detect patterns in images by applying a filter. Though technically different, the terms are used interchangeably in practice.\n",
    "\n",
    "Convolutional Layers:\n",
    "Convolutional layers perform cross-correlation and learn the best filters during training using backpropagation. This allows the model to automatically detect important features like edges, textures, and patterns.\n",
    "\n",
    "Edge Detection Example:\n",
    "By applying a simple kernel like [1, -1] over an image, the model can identify edges by detecting changes in pixel intensities. This is a fundamental operation in image processing.\n",
    "\n",
    "Learning Kernels:\n",
    "Instead of manually designing kernels, convolutional neural networks can learn them from the data. This flexibility allows CNNs to adapt to different types of images and tasks by optimizing the filters during training.\n",
    "\n",
    "Feature Maps and Receptive Fields:\n",
    "A feature map is a result of applying a convolutional filter to an image, indicating where specific features appear. The receptive field of a neuron refers to the region in the input image that influences the neuron's activation, and this grows larger in deeper layers of the network.\n",
    "\n",
    "Multiple Channels:\n",
    "Convolutional layers can handle multiple input channels, such as red, green, and blue (RGB) channels in images. Each channel contributes to feature extraction, allowing CNNs to detect more complex patterns in color images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8526bc87-0412-4c69-b09e-1e4a9730ccf1",
   "metadata": {},
   "source": [
    "## 7.3. Padding and Stride "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fbe060-a5a1-4ff5-9a4a-443631fe35fb",
   "metadata": {},
   "source": [
    "### Take away messages and discussion points\n",
    "\n",
    "Convolution and Cross-Correlation:\n",
    "In deep learning, \"convolution\" refers to cross-correlation, which is used to detect patterns in images. These terms are often used interchangeably.\n",
    "\n",
    "Convolutional Layers:\n",
    "These layers learn filters automatically during training and detect important features like edges and patterns through cross-correlation.\n",
    "\n",
    "Edge Detection:\n",
    "By using a simple filter like [1, -1], models can detect edges in an image by identifying pixel intensity changes.\n",
    "\n",
    "Learning Kernels:\n",
    "Instead of manually creating filters, CNNs learn the best kernels from data, adapting to different tasks and images during training.\n",
    "\n",
    "Feature Maps and Receptive Fields:\n",
    "Feature maps show where certain features appear in an image, and deeper layers expand their receptive field, considering larger image areas.\n",
    "\n",
    "Multiple Channels:\n",
    "CNNs can handle multiple channels, such as RGB in images, to detect more complex patterns by using each channel for feature extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d846f9e3-b0ef-4c88-b2df-0ff65fccdd5c",
   "metadata": {},
   "source": [
    "## 7.4. Multiple Input and Multiple Output Channels "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f523a075-18d8-41c3-83d6-638dddd79dc4",
   "metadata": {},
   "source": [
    "### Take away messages and discussion points\n",
    "\n",
    "Multiple Input Channels:\n",
    "When working with multi-channel inputs (e.g., RGB images), convolution kernels are designed to match the input channels. Each input channel is processed separately, and the results are summed.\n",
    "\n",
    "Multiple Output Channels:\n",
    "Convolutional layers can produce multiple output channels. Each output channel is a result of combining all input channels, allowing the model to detect more complex patterns.\n",
    "\n",
    "1x1 Convolution:\n",
    "A 1x1 convolution operates only across channels, not across spatial dimensions. It is often used to reduce the number of channels while preserving spatial dimensions, and it acts as a fully connected layer applied across each pixel.\n",
    "\n",
    "Channel Flexibility:\n",
    "Multiple channels allow CNNs to capture different features (e.g., edges, textures) simultaneously. This gives CNNs the power to balance local feature detection with the ability to handle complex patterns across multiple layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31249c0-b529-449f-a996-0151e146f3c6",
   "metadata": {},
   "source": [
    "## 7.5. Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce7931b-f3fb-4d7e-bfd7-339e4a3a65be",
   "metadata": {},
   "source": [
    "### Takeaway messages and discussion points\n",
    "\n",
    "Pooling Basics:\n",
    "Pooling layers are used to reduce the spatial dimensions of an image while preserving important features. They help the model be less sensitive to small shifts in the input, such as translations or noise.\n",
    "\n",
    "Max-Pooling vs Average Pooling:\n",
    "Max-pooling selects the maximum value from each window, while average pooling computes the mean. Max-pooling is more common as it captures the strongest features in the image, making the model more invariant to minor changes.\n",
    "\n",
    "Padding and Stride in Pooling:\n",
    "As with convolutional layers, pooling layers can use padding to preserve spatial dimensions or strides to control how much the pooling window moves. This allows flexibility in adjusting the output size.\n",
    "\n",
    "Multiple Channels:\n",
    "Pooling is applied independently to each input channel, meaning the number of output channels remains the same as the input channels. This allows the model to handle multi-channel data, like color images, effectively.\n",
    "\n",
    "Takeaway:\n",
    "Pooling reduces spatial resolution while keeping key features intact, making the model less sensitive to small changes in the input. Max-pooling is generally preferred for its ability to capture dominant patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676d9fb8-89b5-4b59-b840-fc2cfe0e57a8",
   "metadata": {},
   "source": [
    "## 7.6. Convolutional Neural Networks (LeNet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6ccec4-d91e-4399-9b80-7ea584613044",
   "metadata": {},
   "source": [
    "### Takeaway messages and discussion points\n",
    "\n",
    "Introduction to LeNet:\n",
    "LeNet was one of the first CNNs designed to recognize handwritten digits. It consists of two main parts: convolutional layers for feature extraction and fully connected layers for classification.\n",
    "\n",
    "LeNet Architecture:\n",
    "The architecture includes two convolutional layers followed by average pooling and three fully connected layers. Convolutional layers reduce spatial resolution and increase the number of channels, while fully connected layers handle classification.\n",
    "\n",
    "Convolution and Pooling:\n",
    "The convolutional layers in LeNet use a 5x5 kernel with a sigmoid activation function, and average pooling is applied to downsample the input, reducing the spatial dimensions while retaining important features.\n",
    "\n",
    "Dense Block:\n",
    "After the convolutional layers, the output is flattened and passed through fully connected layers, which reduce dimensionality and eventually output class probabilities.\n",
    "\n",
    "Training LeNet:\n",
    "LeNet is trained using cross-entropy loss with stochastic gradient descent. Even though CNNs like LeNet have fewer parameters than MLPs, they are computationally more expensive.\n",
    "\n",
    "Takeaway:\n",
    "LeNet introduced convolutional layers as an effective way to handle image data, revolutionizing image classification. Its architecture remains a foundation for modern CNNs despite its simplicity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f4b48c-286f-4fdc-b9fa-19a26cb420cc",
   "metadata": {},
   "source": [
    "## 8.2. Networks Using Blocks (VGG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34318d5a-cfaf-42f7-a9de-2e1aaebaa556",
   "metadata": {},
   "source": [
    "### Takeaway messages and discussion points\n",
    "\n",
    "VGG Block:\n",
    "VGG introduced the idea of using blocks of multiple small convolution layers (typically 3x3 convolutions) followed by a pooling layer. This approach allows for deeper networks while keeping the model computationally efficient.\n",
    "\n",
    "VGG Architecture:\n",
    "VGG networks stack these convolutional blocks, halving the spatial resolution after each block with max-pooling. The fully connected layers follow the convolutional blocks, similar to AlexNet, but the key difference is that VGG layers are grouped into blocks, allowing for a deeper network structure.\n",
    "\n",
    "Deep and Narrow Design:\n",
    "Simonyan and Zisserman found that deep and narrow networks (with more layers but smaller convolutions) perform better than shallow and wide ones. This design became a standard for deep learning architectures.\n",
    "\n",
    "Training:\n",
    "VGG-11, one of the VGG variants, uses 11 layers, including convolutional and fully connected layers. This architecture is computationally heavier than AlexNet but allows for improved accuracy by leveraging deeper layers.\n",
    "\n",
    "Takeaway:\n",
    "VGG introduced the concept of convolutional blocks, significantly influencing modern deep network designs by promoting deep and narrow architectures that stack small convolutional layers for more efficient learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e651f9-1f30-49a2-b4d4-073d6786d179",
   "metadata": {},
   "source": [
    "## 8.6. Residual Networks (ResNet) and ResNeXt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecfa658-cf93-4b70-9d6e-d3f377e9971b",
   "metadata": {},
   "source": [
    "### Takeaway messages and discussion points\n",
    "\n",
    "Residual Block Concept:\n",
    "ResNet introduced residual blocks to solve the problem of vanishing gradients in deep networks. The residual block uses shortcut connections to add the input directly to the output, allowing the model to learn the difference (residual) between the input and the desired output.\n",
    "\n",
    "Function Classes:\n",
    "In deep networks, adding more layers should ideally make the network more expressive. Residual blocks ensure that added layers don't degrade performance by allowing each layer to learn an identity function if needed.\n",
    "\n",
    "ResNet Architecture:\n",
    "ResNet-18 consists of several residual blocks where two convolutional layers (with batch normalization and ReLU) are followed by shortcut connections. The architecture allows for very deep networks, such as ResNet-152, without performance degradation.\n",
    "\n",
    "ResNeXt:\n",
    "ResNeXt is a variant that builds on ResNet by using grouped convolutions within the residual block. It improves efficiency by reducing the number of parameters and operations while maintaining or improving performance.\n",
    "\n",
    "Training:\n",
    "ResNet is powerful and flexible, allowing for deep architectures that are easier to train compared to earlier models. Training on datasets like Fashion-MNIST shows good results, and ResNet's structure continues to influence the design of modern deep learning models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
